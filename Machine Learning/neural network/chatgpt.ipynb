{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpYjX2_p17_2",
        "outputId": "8c2247fe-b4d9-42ef-d2fa-1f3d6c88ce53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.4.26)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "# === Mount Google Drive ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# === Import libraries ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import tensorflow as tf\n",
        "!pip install keras-tuner\n",
        "import keras_tuner as kt\n",
        "\n",
        "# === Load Data ===\n",
        "# df = pd.read_csv(\"./../../Data/preprocessed_datasets/interactions_prepped_stage3.csv\")\n",
        "file_path = '/content/drive/My Drive/interactions_prepped_stage3.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# === Feature and Target Selection ===\n",
        "target_col = \"Energy\"\n",
        "y = df[target_col]\n",
        "\n",
        "num_cols = [\"R\", \"r\", \"Phi\", \"Theta\", \"Q\", \"P1/P2\"]\n",
        "cat_cols = [\"Amino_acid\", \"Carbohydrate\", \"small_H_position\"]\n",
        "\n",
        "# Numeric data columns\n",
        "X_num = df[num_cols]\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "X_cat = pd.get_dummies(df[cat_cols], prefix=[\"aa\", \"carb\", \"small_h\"], drop_first=True)\n",
        "\n",
        "# Combine numeric and categorical columns\n",
        "X_all = pd.concat([X_num, X_cat], axis=1)\n",
        "\n",
        "# === Normalize Numeric Columns ===\n",
        "scaler = StandardScaler()\n",
        "X_all[num_cols] = scaler.fit_transform(X_all[num_cols])\n",
        "\n",
        "# === Keras Model Builder with Tunable Parameters ===\n",
        "def build_model(hp):\n",
        "    inp = tf.keras.Input(shape=(X_all.shape[1],))\n",
        "    x = tf.keras.layers.Flatten()(inp)\n",
        "\n",
        "    for i in range(hp.Int(\"num_layers\", 2, 5)):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            hp.Int(f\"units_{i}\", 32, 96, step=16),\n",
        "            activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
        "            kernel_initializer=\"he_normal\",\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(\n",
        "                hp.Float(\"l2\", 1e-6, 1e-2, sampling=\"log\")\n",
        "            ),\n",
        "        )(x)\n",
        "        if hp.Boolean(\"use_dropout\"):\n",
        "            x = tf.keras.layers.Dropout(hp.Float(\"dropout\", 0.1, 0.5, step=0.1))(x)\n",
        "\n",
        "    out = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")\n",
        "        ),\n",
        "        loss=\"mse\",\n",
        "        metrics=[\"mae\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "# === Hyperband Tuner Setup ===\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective=\"val_loss\",\n",
        "    max_epochs=100,\n",
        "    factor=3,\n",
        "    directory=\"kt_tuning\",\n",
        "    project_name=\"energy_prediction\",\n",
        "    overwrite=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Early Stopping Callback ===\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=30)\n",
        "\n",
        "# === K-Fold Cross-Validation Loop ===\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_results = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
        "    print(f\"\\nFold {fold+1} Training...\")\n",
        "\n",
        "    X_train, X_val = X_all.iloc[train_idx], X_all.iloc[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    tuner.search(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=100,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "    best_model = tuner.hypermodel.build(best_hp)\n",
        "    best_model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = best_model.predict(X_val).flatten()\n",
        "    fold_mse = mean_squared_error(y_val, y_pred)\n",
        "    fold_mae = mean_absolute_error(y_val, y_pred)\n",
        "    fold_rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    fold_r2 = r2_score(y_val, y_pred)\n",
        "    fold_results.append((fold_mse, fold_mae, fold_rmse, fold_r2))\n",
        "\n",
        "# === Report Summary ===\n",
        "print(\"\\n=== Cross-Validated Results ===\")\n",
        "for i, (mse, mae, rmse, r2) in enumerate(fold_results):\n",
        "    print(f\"Fold {i+1}: MSE={mse:.3f}, MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.3f}\")\n",
        "\n",
        "avg_mse = np.mean([res[0] for res in fold_results])\n",
        "avg_mae = np.mean([res[1] for res in fold_results])\n",
        "avg_rmse = np.mean([res[2] for res in fold_results])\n",
        "avg_r2 = np.mean([res[3] for res in fold_results])\n",
        "\n",
        "print(\n",
        "    f\"\\nFinal Avg Results: MSE={avg_mse:.3f}, MAE={avg_mae:.3f}, RMSE={avg_rmse:.3f}, R2={avg_r2:.3f}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smTGxPDR2HDv",
        "outputId": "2717d329-d974-466b-fc66-c0c62e8dd41e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 254 Complete [00h 00m 32s]\n",
            "val_loss: 64.022705078125\n",
            "\n",
            "Best val_loss So Far: 41.7783203125\n",
            "Total elapsed time: 00h 32m 37s\n",
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 415.5855 - mae: 17.9067 - val_loss: 127.0455 - val_mae: 8.8940\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 114.2130 - mae: 8.2124 - val_loss: 66.7731 - val_mae: 6.7951\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 63.4304 - mae: 6.3857 - val_loss: 64.6079 - val_mae: 6.6259\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 61.5301 - mae: 6.2737 - val_loss: 55.9606 - val_mae: 6.1229\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 56.5274 - mae: 5.8860 - val_loss: 51.5982 - val_mae: 5.7711\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 48.2102 - mae: 5.3283 - val_loss: 46.8317 - val_mae: 5.4202\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.0763 - mae: 5.1204 - val_loss: 47.8891 - val_mae: 5.4532\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 46.6367 - mae: 5.2458 - val_loss: 45.9206 - val_mae: 5.2967\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 41.4435 - mae: 4.9001 - val_loss: 46.6515 - val_mae: 5.3665\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.5218 - mae: 5.0803 - val_loss: 44.5858 - val_mae: 5.1793\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.4453 - mae: 5.1237 - val_loss: 46.3705 - val_mae: 5.3158\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 40.0673 - mae: 4.9259 - val_loss: 45.1806 - val_mae: 5.1868\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 42.2804 - mae: 4.9066 - val_loss: 45.5209 - val_mae: 5.2550\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 43.7400 - mae: 5.1571 - val_loss: 44.6879 - val_mae: 5.1718\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 36.4945 - mae: 4.6974 - val_loss: 43.7798 - val_mae: 5.0905\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 40.5383 - mae: 4.8389 - val_loss: 45.9570 - val_mae: 5.2193\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.6746 - mae: 4.5645 - val_loss: 47.5150 - val_mae: 5.3134\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 37.8344 - mae: 4.8233 - val_loss: 45.1373 - val_mae: 5.2017\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 35.2396 - mae: 4.4749 - val_loss: 46.9833 - val_mae: 5.3544\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 39.9383 - mae: 4.9320 - val_loss: 44.5909 - val_mae: 5.1778\n",
            "Epoch 21/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.5898 - mae: 4.4142 - val_loss: 46.0646 - val_mae: 5.2413\n",
            "Epoch 22/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 38.6414 - mae: 4.7854 - val_loss: 46.5157 - val_mae: 5.3041\n",
            "Epoch 23/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.0791 - mae: 4.6533 - val_loss: 44.8264 - val_mae: 5.2020\n",
            "Epoch 24/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 36.0878 - mae: 4.6646 - val_loss: 46.0908 - val_mae: 5.2624\n",
            "Epoch 25/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8978 - mae: 4.3574 - val_loss: 46.8827 - val_mae: 5.2757\n",
            "Epoch 26/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8132 - mae: 4.3457 - val_loss: 44.5098 - val_mae: 5.1669\n",
            "Epoch 27/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.4837 - mae: 4.4173 - val_loss: 47.9848 - val_mae: 5.3805\n",
            "Epoch 28/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.3997 - mae: 4.3766 - val_loss: 46.0681 - val_mae: 5.2529\n",
            "Epoch 29/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.1767 - mae: 4.2628 - val_loss: 45.9034 - val_mae: 5.2165\n",
            "Epoch 30/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 34.2333 - mae: 4.4144 - val_loss: 45.4098 - val_mae: 5.2620\n",
            "Epoch 31/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2519 - mae: 4.2051 - val_loss: 46.7944 - val_mae: 5.3430\n",
            "Epoch 32/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1674 - mae: 4.2522 - val_loss: 48.6278 - val_mae: 5.4336\n",
            "Epoch 33/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.4330 - mae: 4.2470 - val_loss: 46.9685 - val_mae: 5.3603\n",
            "Epoch 34/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.5449 - mae: 4.2491 - val_loss: 46.7767 - val_mae: 5.3245\n",
            "Epoch 35/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.3722 - mae: 4.0129 - val_loss: 46.7384 - val_mae: 5.2823\n",
            "Epoch 36/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.6467 - mae: 4.1180 - val_loss: 47.7279 - val_mae: 5.3677\n",
            "Epoch 37/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.7455 - mae: 4.1108 - val_loss: 46.8943 - val_mae: 5.3794\n",
            "Epoch 38/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.1944 - mae: 4.0631 - val_loss: 46.6446 - val_mae: 5.3195\n",
            "Epoch 39/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.4060 - mae: 4.0906 - val_loss: 47.1989 - val_mae: 5.3715\n",
            "Epoch 40/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0618 - mae: 4.2671 - val_loss: 48.8352 - val_mae: 5.4579\n",
            "Epoch 41/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.8836 - mae: 4.2226 - val_loss: 47.0617 - val_mae: 5.3250\n",
            "Epoch 42/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.7153 - mae: 4.0319 - val_loss: 45.7842 - val_mae: 5.2163\n",
            "Epoch 43/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2270 - mae: 4.1080 - val_loss: 47.2793 - val_mae: 5.2961\n",
            "Epoch 44/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 26.1162 - mae: 4.0219 - val_loss: 48.6149 - val_mae: 5.3379\n",
            "Epoch 45/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.1900 - mae: 4.0130 - val_loss: 47.1613 - val_mae: 5.2977\n",
            "Epoch 46/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.7011 - mae: 3.9564 - val_loss: 46.9172 - val_mae: 5.3054\n",
            "Epoch 47/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.6022 - mae: 3.8895 - val_loss: 49.3293 - val_mae: 5.4224\n",
            "Epoch 48/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.3976 - mae: 3.9443 - val_loss: 46.2928 - val_mae: 5.2862\n",
            "Epoch 49/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 24.1066 - mae: 3.8750 - val_loss: 46.9327 - val_mae: 5.2647\n",
            "Epoch 50/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.5127 - mae: 3.7632 - val_loss: 46.7645 - val_mae: 5.2877\n",
            "Epoch 51/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.0008 - mae: 4.0890 - val_loss: 49.0754 - val_mae: 5.4379\n",
            "Epoch 52/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24.9786 - mae: 3.8750 - val_loss: 48.9635 - val_mae: 5.3801\n",
            "Epoch 53/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.8267 - mae: 4.0125 - val_loss: 48.0101 - val_mae: 5.3647\n",
            "Epoch 54/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.8752 - mae: 3.8891 - val_loss: 49.4984 - val_mae: 5.4290\n",
            "Epoch 55/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.5712 - mae: 3.8194 - val_loss: 47.8034 - val_mae: 5.3316\n",
            "Epoch 56/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 25.7767 - mae: 3.8239 - val_loss: 48.3408 - val_mae: 5.3394\n",
            "Epoch 57/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.3286 - mae: 4.1052 - val_loss: 47.0901 - val_mae: 5.2744\n",
            "Epoch 58/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.3596 - mae: 3.9142 - val_loss: 46.6424 - val_mae: 5.2331\n",
            "Epoch 59/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.6272 - mae: 3.6921 - val_loss: 49.6227 - val_mae: 5.4110\n",
            "Epoch 60/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.5124 - mae: 3.9073 - val_loss: 48.9300 - val_mae: 5.3323\n",
            "Epoch 61/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.5513 - mae: 3.7665 - val_loss: 48.2377 - val_mae: 5.3455\n",
            "Epoch 62/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 23.3494 - mae: 3.8909 - val_loss: 47.0381 - val_mae: 5.2800\n",
            "Epoch 63/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.6723 - mae: 3.7454 - val_loss: 47.9059 - val_mae: 5.3512\n",
            "Epoch 64/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.5893 - mae: 3.8441 - val_loss: 47.3980 - val_mae: 5.2667\n",
            "Epoch 65/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 24.3619 - mae: 3.7710 - val_loss: 49.0891 - val_mae: 5.3706\n",
            "Epoch 66/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 22.1185 - mae: 3.7217 - val_loss: 48.8297 - val_mae: 5.3709\n",
            "Epoch 67/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 25.4420 - mae: 3.9365 - val_loss: 48.7222 - val_mae: 5.3126\n",
            "Epoch 68/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 23.3129 - mae: 3.7100 - val_loss: 48.0994 - val_mae: 5.3523\n",
            "Epoch 69/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 25.2098 - mae: 3.8959 - val_loss: 48.5149 - val_mae: 5.3428\n",
            "Epoch 70/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 22.6708 - mae: 3.7458 - val_loss: 48.8027 - val_mae: 5.3442\n",
            "Epoch 71/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21.0950 - mae: 3.5672 - val_loss: 48.4082 - val_mae: 5.3484\n",
            "Epoch 72/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21.5196 - mae: 3.6247 - val_loss: 51.6023 - val_mae: 5.4951\n",
            "Epoch 73/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 22.6538 - mae: 3.6549 - val_loss: 49.0338 - val_mae: 5.2735\n",
            "Epoch 74/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 21.5646 - mae: 3.5612 - val_loss: 49.8859 - val_mae: 5.4291\n",
            "Epoch 75/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 27.4414 - mae: 4.0111 - val_loss: 48.1634 - val_mae: 5.2841\n",
            "Epoch 76/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.3020 - mae: 3.3142 - val_loss: 49.2235 - val_mae: 5.3868\n",
            "Epoch 77/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.5642 - mae: 3.4636 - val_loss: 48.4148 - val_mae: 5.3517\n",
            "Epoch 78/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 25.1611 - mae: 3.8104 - val_loss: 47.6251 - val_mae: 5.3193\n",
            "Epoch 79/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.0771 - mae: 3.8216 - val_loss: 47.1031 - val_mae: 5.2480\n",
            "Epoch 80/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23.7976 - mae: 3.8612 - val_loss: 47.7628 - val_mae: 5.3183\n",
            "Epoch 81/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.1863 - mae: 3.3545 - val_loss: 50.5553 - val_mae: 5.5134\n",
            "Epoch 82/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.8263 - mae: 3.6250 - val_loss: 48.9002 - val_mae: 5.3478\n",
            "Epoch 83/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 23.4768 - mae: 3.6502 - val_loss: 49.2363 - val_mae: 5.4296\n",
            "Epoch 84/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23.2641 - mae: 3.7472 - val_loss: 48.2576 - val_mae: 5.3532\n",
            "Epoch 85/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.2384 - mae: 3.6490 - val_loss: 49.1956 - val_mae: 5.4256\n",
            "Epoch 86/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.6656 - mae: 3.6805 - val_loss: 48.8157 - val_mae: 5.3486\n",
            "Epoch 87/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.1621 - mae: 3.5847 - val_loss: 49.4541 - val_mae: 5.3977\n",
            "Epoch 88/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.8337 - mae: 3.3061 - val_loss: 48.5484 - val_mae: 5.3491\n",
            "Epoch 89/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 19.6596 - mae: 3.3277 - val_loss: 50.0698 - val_mae: 5.4230\n",
            "Epoch 90/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.1020 - mae: 3.4844 - val_loss: 49.4997 - val_mae: 5.4116\n",
            "Epoch 91/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.7073 - mae: 3.5415 - val_loss: 50.3604 - val_mae: 5.5136\n",
            "Epoch 92/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.7145 - mae: 3.7094 - val_loss: 51.2519 - val_mae: 5.5075\n",
            "Epoch 93/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.6449 - mae: 3.7009 - val_loss: 53.4491 - val_mae: 5.6943\n",
            "Epoch 94/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.5018 - mae: 3.6049 - val_loss: 49.5376 - val_mae: 5.4037\n",
            "Epoch 95/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 24.8210 - mae: 3.8976 - val_loss: 49.7042 - val_mae: 5.4640\n",
            "Epoch 96/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.1479 - mae: 3.5962 - val_loss: 50.0467 - val_mae: 5.4476\n",
            "Epoch 97/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.2611 - mae: 3.3638 - val_loss: 49.3528 - val_mae: 5.3811\n",
            "Epoch 98/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.4778 - mae: 3.5699 - val_loss: 49.1560 - val_mae: 5.3583\n",
            "Epoch 99/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20.6605 - mae: 3.5149 - val_loss: 49.6800 - val_mae: 5.4315\n",
            "Epoch 100/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.4220 - mae: 3.5524 - val_loss: 48.3609 - val_mae: 5.2967\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\n",
            "Fold 2 Training...\n",
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 442.2670 - mae: 18.7179 - val_loss: 122.4275 - val_mae: 9.1577\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 119.6965 - mae: 8.8598 - val_loss: 58.0305 - val_mae: 6.1363\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 76.7267 - mae: 7.2831 - val_loss: 56.9400 - val_mae: 6.0793\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 65.0217 - mae: 6.5983 - val_loss: 40.0044 - val_mae: 5.1055\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 62.3977 - mae: 5.9582 - val_loss: 37.6984 - val_mae: 4.9505\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 54.4732 - mae: 5.8330 - val_loss: 34.7013 - val_mae: 4.7164\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 52.4199 - mae: 5.6573 - val_loss: 34.6565 - val_mae: 4.7107\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.3169 - mae: 5.2301 - val_loss: 34.2852 - val_mae: 4.6830\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 46.6585 - mae: 5.2700 - val_loss: 34.9282 - val_mae: 4.7417\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 42.9583 - mae: 5.1098 - val_loss: 35.6948 - val_mae: 4.8060\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 43.3942 - mae: 5.0965 - val_loss: 33.5102 - val_mae: 4.6294\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 41.2727 - mae: 5.0787 - val_loss: 35.2760 - val_mae: 4.7692\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.8291 - mae: 5.1329 - val_loss: 33.9102 - val_mae: 4.6356\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 40.0910 - mae: 4.6974 - val_loss: 35.9339 - val_mae: 4.8075\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 42.9811 - mae: 4.8321 - val_loss: 36.3559 - val_mae: 4.8350\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 38.9257 - mae: 4.9336 - val_loss: 33.2087 - val_mae: 4.5890\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.4221 - mae: 5.1142 - val_loss: 34.8924 - val_mae: 4.6935\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 41.5239 - mae: 4.9302 - val_loss: 34.9494 - val_mae: 4.6859\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 39.6151 - mae: 4.8242 - val_loss: 34.4704 - val_mae: 4.6578\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 39.0163 - mae: 4.8867 - val_loss: 35.9459 - val_mae: 4.7665\n",
            "Epoch 21/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 42.1001 - mae: 4.9420 - val_loss: 34.6493 - val_mae: 4.6371\n",
            "Epoch 22/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 36.3080 - mae: 4.6412 - val_loss: 33.9585 - val_mae: 4.5747\n",
            "Epoch 23/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 36.3687 - mae: 4.4848 - val_loss: 34.4282 - val_mae: 4.6394\n",
            "Epoch 24/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 34.9242 - mae: 4.5946 - val_loss: 33.2650 - val_mae: 4.5713\n",
            "Epoch 25/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 35.4322 - mae: 4.4625 - val_loss: 34.2197 - val_mae: 4.6473\n",
            "Epoch 26/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 34.6141 - mae: 4.5161 - val_loss: 33.2365 - val_mae: 4.5730\n",
            "Epoch 27/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 30.8296 - mae: 4.2524 - val_loss: 34.3911 - val_mae: 4.6591\n",
            "Epoch 28/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 40.0666 - mae: 4.7402 - val_loss: 34.8850 - val_mae: 4.6578\n",
            "Epoch 29/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 33.3402 - mae: 4.4031 - val_loss: 32.4161 - val_mae: 4.4583\n",
            "Epoch 30/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 32.2187 - mae: 4.3110 - val_loss: 33.3216 - val_mae: 4.5483\n",
            "Epoch 31/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 38.0819 - mae: 4.7381 - val_loss: 32.1362 - val_mae: 4.4356\n",
            "Epoch 32/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.6859 - mae: 4.2577 - val_loss: 33.8827 - val_mae: 4.5480\n",
            "Epoch 33/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.6238 - mae: 4.1082 - val_loss: 33.7239 - val_mae: 4.5085\n",
            "Epoch 34/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.4785 - mae: 4.1453 - val_loss: 33.8134 - val_mae: 4.5698\n",
            "Epoch 35/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.5706 - mae: 4.4491 - val_loss: 32.6010 - val_mae: 4.4700\n",
            "Epoch 36/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 32.4331 - mae: 4.2558 - val_loss: 31.5489 - val_mae: 4.3748\n",
            "Epoch 37/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.1782 - mae: 4.1722 - val_loss: 33.4276 - val_mae: 4.5223\n",
            "Epoch 38/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8862 - mae: 4.2916 - val_loss: 33.1308 - val_mae: 4.5220\n",
            "Epoch 39/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.3075 - mae: 4.1330 - val_loss: 32.0155 - val_mae: 4.4237\n",
            "Epoch 40/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 35.1431 - mae: 4.5736 - val_loss: 30.5911 - val_mae: 4.3073\n",
            "Epoch 41/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.5482 - mae: 4.2887 - val_loss: 32.4684 - val_mae: 4.4694\n",
            "Epoch 42/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.8107 - mae: 3.9583 - val_loss: 34.1066 - val_mae: 4.5757\n",
            "Epoch 43/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.6965 - mae: 4.2900 - val_loss: 31.0313 - val_mae: 4.2786\n",
            "Epoch 44/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.8614 - mae: 3.7938 - val_loss: 31.8769 - val_mae: 4.3613\n",
            "Epoch 45/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.6736 - mae: 3.7686 - val_loss: 32.3259 - val_mae: 4.4171\n",
            "Epoch 46/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.5793 - mae: 4.1647 - val_loss: 31.8897 - val_mae: 4.3678\n",
            "Epoch 47/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24.9066 - mae: 3.8211 - val_loss: 31.3821 - val_mae: 4.3457\n",
            "Epoch 48/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.3483 - mae: 3.9831 - val_loss: 32.2748 - val_mae: 4.4465\n",
            "Epoch 49/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.4895 - mae: 4.0287 - val_loss: 33.8741 - val_mae: 4.5438\n",
            "Epoch 50/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4076 - mae: 4.0426 - val_loss: 32.5994 - val_mae: 4.4733\n",
            "Epoch 51/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.9318 - mae: 4.1867 - val_loss: 32.0320 - val_mae: 4.4037\n",
            "Epoch 52/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 25.5274 - mae: 3.9006 - val_loss: 32.1037 - val_mae: 4.4136\n",
            "Epoch 53/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.5891 - mae: 3.8395 - val_loss: 30.4737 - val_mae: 4.2514\n",
            "Epoch 54/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.0071 - mae: 3.8851 - val_loss: 32.3935 - val_mae: 4.4283\n",
            "Epoch 55/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.7647 - mae: 3.7637 - val_loss: 31.6247 - val_mae: 4.3853\n",
            "Epoch 56/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24.0804 - mae: 3.8358 - val_loss: 31.1756 - val_mae: 4.3588\n",
            "Epoch 57/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.4541 - mae: 4.0010 - val_loss: 31.4374 - val_mae: 4.3531\n",
            "Epoch 58/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.6379 - mae: 3.7963 - val_loss: 30.9768 - val_mae: 4.3132\n",
            "Epoch 59/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.5899 - mae: 4.0097 - val_loss: 32.5700 - val_mae: 4.3936\n",
            "Epoch 60/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.6903 - mae: 3.8789 - val_loss: 31.7010 - val_mae: 4.3365\n",
            "Epoch 61/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.9136 - mae: 3.8424 - val_loss: 32.8428 - val_mae: 4.4588\n",
            "Epoch 62/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4455 - mae: 4.0318 - val_loss: 31.3982 - val_mae: 4.3220\n",
            "Epoch 63/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.1532 - mae: 4.0385 - val_loss: 31.8691 - val_mae: 4.3360\n",
            "Epoch 64/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.8785 - mae: 3.8168 - val_loss: 30.3731 - val_mae: 4.2256\n",
            "Epoch 65/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.2383 - mae: 3.6705 - val_loss: 33.9196 - val_mae: 4.5365\n",
            "Epoch 66/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.2856 - mae: 3.7490 - val_loss: 32.3805 - val_mae: 4.3824\n",
            "Epoch 67/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.5844 - mae: 3.8114 - val_loss: 32.0493 - val_mae: 4.3399\n",
            "Epoch 68/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.3719 - mae: 4.2221 - val_loss: 30.3199 - val_mae: 4.2477\n",
            "Epoch 69/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.4563 - mae: 3.6959 - val_loss: 31.5201 - val_mae: 4.3405\n",
            "Epoch 70/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.4799 - mae: 3.9866 - val_loss: 32.3475 - val_mae: 4.4932\n",
            "Epoch 71/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.9835 - mae: 3.6361 - val_loss: 32.0160 - val_mae: 4.3774\n",
            "Epoch 72/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.5406 - mae: 3.8649 - val_loss: 32.2934 - val_mae: 4.3857\n",
            "Epoch 73/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.9523 - mae: 3.6696 - val_loss: 30.2829 - val_mae: 4.2841\n",
            "Epoch 74/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 26.2389 - mae: 3.8892 - val_loss: 32.0722 - val_mae: 4.3979\n",
            "Epoch 75/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.8421 - mae: 3.7537 - val_loss: 31.4258 - val_mae: 4.3447\n",
            "Epoch 76/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.1908 - mae: 3.9601 - val_loss: 31.8490 - val_mae: 4.3851\n",
            "Epoch 77/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.6255 - mae: 3.6629 - val_loss: 31.7800 - val_mae: 4.3987\n",
            "Epoch 78/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.3521 - mae: 3.8292 - val_loss: 31.9484 - val_mae: 4.4136\n",
            "Epoch 79/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.7581 - mae: 3.7641 - val_loss: 32.7673 - val_mae: 4.4541\n",
            "Epoch 80/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24.9926 - mae: 3.7575 - val_loss: 30.7828 - val_mae: 4.2901\n",
            "Epoch 81/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.7073 - mae: 3.7827 - val_loss: 33.8809 - val_mae: 4.5296\n",
            "Epoch 82/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.7934 - mae: 3.7670 - val_loss: 32.7318 - val_mae: 4.4445\n",
            "Epoch 83/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.9665 - mae: 3.9390 - val_loss: 33.0482 - val_mae: 4.4428\n",
            "Epoch 84/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.5669 - mae: 3.6845 - val_loss: 32.2183 - val_mae: 4.3832\n",
            "Epoch 85/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.7796 - mae: 3.6954 - val_loss: 32.1740 - val_mae: 4.4482\n",
            "Epoch 86/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.1385 - mae: 3.6781 - val_loss: 33.5325 - val_mae: 4.5362\n",
            "Epoch 87/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.8985 - mae: 3.7165 - val_loss: 31.2522 - val_mae: 4.3767\n",
            "Epoch 88/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 22.0660 - mae: 3.5979 - val_loss: 32.7729 - val_mae: 4.4100\n",
            "Epoch 89/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 25.3837 - mae: 3.7956 - val_loss: 32.0055 - val_mae: 4.3727\n",
            "Epoch 90/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 22.3599 - mae: 3.6494 - val_loss: 32.6073 - val_mae: 4.4233\n",
            "Epoch 91/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 20.0217 - mae: 3.4083 - val_loss: 31.8733 - val_mae: 4.3774\n",
            "Epoch 92/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23.5389 - mae: 3.6049 - val_loss: 31.3326 - val_mae: 4.2871\n",
            "Epoch 93/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 23.0996 - mae: 3.6771 - val_loss: 33.5610 - val_mae: 4.4846\n",
            "Epoch 94/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 25.1329 - mae: 3.7377 - val_loss: 31.8386 - val_mae: 4.4073\n",
            "Epoch 95/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 20.3505 - mae: 3.4273 - val_loss: 33.3849 - val_mae: 4.5196\n",
            "Epoch 96/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21.3582 - mae: 3.5234 - val_loss: 32.7380 - val_mae: 4.4722\n",
            "Epoch 97/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 21.5853 - mae: 3.6375 - val_loss: 32.5990 - val_mae: 4.3823\n",
            "Epoch 98/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.3780 - mae: 3.6541 - val_loss: 34.9135 - val_mae: 4.5991\n",
            "Epoch 99/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.9384 - mae: 3.4690 - val_loss: 31.6990 - val_mae: 4.3639\n",
            "Epoch 100/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.8263 - mae: 3.4170 - val_loss: 32.8159 - val_mae: 4.4947\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\n",
            "Fold 3 Training...\n",
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 396.7905 - mae: 17.6794 - val_loss: 179.3353 - val_mae: 10.7845\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 101.1660 - mae: 7.6478 - val_loss: 86.8002 - val_mae: 7.5062\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 62.5325 - mae: 6.5069 - val_loss: 88.1054 - val_mae: 7.3930\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 56.2742 - mae: 5.9669 - val_loss: 85.1736 - val_mae: 7.2388\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 51.2696 - mae: 5.7151 - val_loss: 76.9007 - val_mae: 6.8084\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 48.6946 - mae: 5.5167 - val_loss: 68.7595 - val_mae: 6.3556\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.3657 - mae: 4.7582 - val_loss: 64.0690 - val_mae: 6.1096\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 39.9236 - mae: 5.0283 - val_loss: 62.5843 - val_mae: 6.0849\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 35.0103 - mae: 4.7188 - val_loss: 61.4273 - val_mae: 6.0039\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 34.0130 - mae: 4.5106 - val_loss: 63.6846 - val_mae: 6.0982\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.4757 - mae: 4.6283 - val_loss: 61.3383 - val_mae: 6.0123\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 35.4241 - mae: 4.6024 - val_loss: 63.2981 - val_mae: 6.0855\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.6388 - mae: 4.5460 - val_loss: 59.6694 - val_mae: 5.9693\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.9073 - mae: 4.5821 - val_loss: 61.3964 - val_mae: 5.9946\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.9141 - mae: 4.7530 - val_loss: 59.8489 - val_mae: 5.9262\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 33.2470 - mae: 4.4774 - val_loss: 61.1403 - val_mae: 5.9899\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.0515 - mae: 4.3214 - val_loss: 59.5506 - val_mae: 6.0071\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.5329 - mae: 4.5737 - val_loss: 62.6125 - val_mae: 6.0601\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.9778 - mae: 4.6428 - val_loss: 61.3493 - val_mae: 6.0849\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.3361 - mae: 4.4595 - val_loss: 63.2267 - val_mae: 6.0930\n",
            "Epoch 21/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.6310 - mae: 4.3563 - val_loss: 60.8166 - val_mae: 6.0362\n",
            "Epoch 22/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.3256 - mae: 4.3043 - val_loss: 60.3435 - val_mae: 6.0371\n",
            "Epoch 23/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.2689 - mae: 4.3924 - val_loss: 60.8582 - val_mae: 6.0569\n",
            "Epoch 24/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.9144 - mae: 3.9235 - val_loss: 60.8172 - val_mae: 5.9938\n",
            "Epoch 25/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.5446 - mae: 4.2259 - val_loss: 60.2161 - val_mae: 6.0356\n",
            "Epoch 26/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.4126 - mae: 4.0153 - val_loss: 63.0473 - val_mae: 6.1328\n",
            "Epoch 27/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.1526 - mae: 4.1347 - val_loss: 59.4162 - val_mae: 6.0087\n",
            "Epoch 28/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.2374 - mae: 4.1400 - val_loss: 60.5202 - val_mae: 6.0231\n",
            "Epoch 29/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.7996 - mae: 4.3290 - val_loss: 58.6175 - val_mae: 5.9286\n",
            "Epoch 30/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.3618 - mae: 4.3275 - val_loss: 61.3977 - val_mae: 5.9965\n",
            "Epoch 31/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.7504 - mae: 4.1184 - val_loss: 61.3517 - val_mae: 5.9949\n",
            "Epoch 32/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.5730 - mae: 4.1731 - val_loss: 58.1227 - val_mae: 5.9239\n",
            "Epoch 33/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 25.9606 - mae: 3.9032 - val_loss: 61.1527 - val_mae: 5.9366\n",
            "Epoch 34/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.8060 - mae: 4.1918 - val_loss: 60.5382 - val_mae: 5.9656\n",
            "Epoch 35/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.7724 - mae: 3.9656 - val_loss: 61.9036 - val_mae: 5.9499\n",
            "Epoch 36/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.9045 - mae: 4.1752 - val_loss: 60.4620 - val_mae: 5.9451\n",
            "Epoch 37/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.0594 - mae: 3.9721 - val_loss: 61.3771 - val_mae: 5.9067\n",
            "Epoch 38/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.6388 - mae: 4.0136 - val_loss: 62.3676 - val_mae: 5.9610\n",
            "Epoch 39/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.8189 - mae: 3.9059 - val_loss: 61.1660 - val_mae: 5.8982\n",
            "Epoch 40/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.8307 - mae: 3.8181 - val_loss: 61.5838 - val_mae: 5.9875\n",
            "Epoch 41/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 26.0891 - mae: 3.9253 - val_loss: 61.7429 - val_mae: 5.9743\n",
            "Epoch 42/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.7727 - mae: 3.6425 - val_loss: 63.6379 - val_mae: 6.0294\n",
            "Epoch 43/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 28.3005 - mae: 4.0555 - val_loss: 61.6628 - val_mae: 5.9175\n",
            "Epoch 44/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 25.4648 - mae: 3.8848 - val_loss: 60.7377 - val_mae: 5.9337\n",
            "Epoch 45/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 30.3242 - mae: 4.2175 - val_loss: 62.8087 - val_mae: 6.0152\n",
            "Epoch 46/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.3571 - mae: 3.9383 - val_loss: 66.0924 - val_mae: 6.0634\n",
            "Epoch 47/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 28.1301 - mae: 4.1793 - val_loss: 60.9464 - val_mae: 5.9201\n",
            "Epoch 48/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 27.9997 - mae: 3.9624 - val_loss: 60.5987 - val_mae: 5.8473\n",
            "Epoch 49/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 26.0535 - mae: 3.8433 - val_loss: 60.9693 - val_mae: 5.9032\n",
            "Epoch 50/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 26.7215 - mae: 3.8364 - val_loss: 64.6032 - val_mae: 5.9687\n",
            "Epoch 51/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 22.6952 - mae: 3.7775 - val_loss: 64.3469 - val_mae: 6.0231\n",
            "Epoch 52/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 26.2203 - mae: 3.8996 - val_loss: 62.1099 - val_mae: 5.9056\n",
            "Epoch 53/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23.4369 - mae: 3.7348 - val_loss: 64.1588 - val_mae: 5.9999\n",
            "Epoch 54/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 20.8861 - mae: 3.5327 - val_loss: 64.1118 - val_mae: 6.0382\n",
            "Epoch 55/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.7174 - mae: 3.9215 - val_loss: 62.2891 - val_mae: 6.0102\n",
            "Epoch 56/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.3411 - mae: 3.8321 - val_loss: 66.6568 - val_mae: 6.0751\n",
            "Epoch 57/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.7379 - mae: 3.5834 - val_loss: 61.7217 - val_mae: 5.9515\n",
            "Epoch 58/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.4966 - mae: 3.5109 - val_loss: 66.6047 - val_mae: 6.0149\n",
            "Epoch 59/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 25.0029 - mae: 3.8627 - val_loss: 65.5522 - val_mae: 6.0931\n",
            "Epoch 60/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.4086 - mae: 3.6245 - val_loss: 64.2017 - val_mae: 6.0086\n",
            "Epoch 61/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.8325 - mae: 3.5803 - val_loss: 67.4358 - val_mae: 6.0372\n",
            "Epoch 62/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.9420 - mae: 3.4847 - val_loss: 63.7910 - val_mae: 5.9811\n",
            "Epoch 63/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 21.7480 - mae: 3.5348 - val_loss: 63.1468 - val_mae: 5.9448\n",
            "Epoch 64/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.8881 - mae: 3.4723 - val_loss: 63.2996 - val_mae: 5.9471\n",
            "Epoch 65/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.2689 - mae: 3.3326 - val_loss: 65.0296 - val_mae: 6.0465\n",
            "Epoch 66/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.7914 - mae: 3.5707 - val_loss: 66.9759 - val_mae: 6.0643\n",
            "Epoch 67/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.7227 - mae: 3.3665 - val_loss: 62.9816 - val_mae: 6.0461\n",
            "Epoch 68/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.4632 - mae: 3.7988 - val_loss: 66.2152 - val_mae: 5.9987\n",
            "Epoch 69/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 22.2499 - mae: 3.6540 - val_loss: 63.8282 - val_mae: 5.9138\n",
            "Epoch 70/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.2541 - mae: 3.6897 - val_loss: 67.1133 - val_mae: 5.9788\n",
            "Epoch 71/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.1727 - mae: 3.5677 - val_loss: 65.0668 - val_mae: 6.0139\n",
            "Epoch 72/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 22.6748 - mae: 3.5841 - val_loss: 64.4343 - val_mae: 5.9135\n",
            "Epoch 73/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21.2552 - mae: 3.5032 - val_loss: 65.7764 - val_mae: 6.0564\n",
            "Epoch 74/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.4717 - mae: 3.8795 - val_loss: 65.7853 - val_mae: 5.9869\n",
            "Epoch 75/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.7958 - mae: 3.5938 - val_loss: 65.5649 - val_mae: 6.0322\n",
            "Epoch 76/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20.9485 - mae: 3.5103 - val_loss: 64.8538 - val_mae: 6.0390\n",
            "Epoch 77/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.0559 - mae: 3.5456 - val_loss: 65.9418 - val_mae: 5.9198\n",
            "Epoch 78/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20.5112 - mae: 3.5002 - val_loss: 64.6656 - val_mae: 6.0094\n",
            "Epoch 79/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.5977 - mae: 3.5882 - val_loss: 66.1884 - val_mae: 5.9829\n",
            "Epoch 80/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.7699 - mae: 3.6788 - val_loss: 66.3502 - val_mae: 6.0010\n",
            "Epoch 81/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.1876 - mae: 3.4854 - val_loss: 64.3008 - val_mae: 5.9704\n",
            "Epoch 82/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20.8119 - mae: 3.4925 - val_loss: 64.4671 - val_mae: 5.9891\n",
            "Epoch 83/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.1660 - mae: 3.6524 - val_loss: 69.9559 - val_mae: 6.1512\n",
            "Epoch 84/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.3153 - mae: 3.5100 - val_loss: 64.9118 - val_mae: 6.0130\n",
            "Epoch 85/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.8221 - mae: 3.3116 - val_loss: 65.5943 - val_mae: 6.0252\n",
            "Epoch 86/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.2710 - mae: 3.3080 - val_loss: 68.1066 - val_mae: 6.0048\n",
            "Epoch 87/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.0488 - mae: 3.4729 - val_loss: 65.9948 - val_mae: 6.0382\n",
            "Epoch 88/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.8574 - mae: 3.3249 - val_loss: 66.6548 - val_mae: 6.0438\n",
            "Epoch 89/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.4366 - mae: 3.5160 - val_loss: 67.8358 - val_mae: 6.0174\n",
            "Epoch 90/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.1012 - mae: 3.4850 - val_loss: 64.1549 - val_mae: 6.0194\n",
            "Epoch 91/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.7695 - mae: 3.4621 - val_loss: 68.5909 - val_mae: 6.0188\n",
            "Epoch 92/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 19.8015 - mae: 3.4555 - val_loss: 65.2901 - val_mae: 5.9597\n",
            "Epoch 93/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.3391 - mae: 3.4854 - val_loss: 67.1947 - val_mae: 6.0410\n",
            "Epoch 94/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.7327 - mae: 3.5446 - val_loss: 69.8081 - val_mae: 6.1025\n",
            "Epoch 95/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.2323 - mae: 3.4798 - val_loss: 65.8163 - val_mae: 6.0382\n",
            "Epoch 96/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 22.9623 - mae: 3.6314 - val_loss: 65.4409 - val_mae: 5.8812\n",
            "Epoch 97/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.6922 - mae: 3.3317 - val_loss: 62.4466 - val_mae: 5.9157\n",
            "Epoch 98/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.2144 - mae: 3.4146 - val_loss: 65.1076 - val_mae: 5.9918\n",
            "Epoch 99/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.0892 - mae: 3.3791 - val_loss: 68.0748 - val_mae: 6.0886\n",
            "Epoch 100/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.0936 - mae: 3.4670 - val_loss: 65.6619 - val_mae: 6.0866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79ac261f7420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79ac261f7420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\n",
            "Fold 4 Training...\n",
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 418.2812 - mae: 18.0245 - val_loss: 138.0178 - val_mae: 9.1540\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 100.0199 - mae: 7.8081 - val_loss: 71.8699 - val_mae: 6.8658\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 66.8354 - mae: 6.4525 - val_loss: 61.1219 - val_mae: 6.2169\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 66.4538 - mae: 6.5326 - val_loss: 53.2084 - val_mae: 5.7581\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 56.8372 - mae: 5.9664 - val_loss: 47.8352 - val_mae: 5.4232\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 52.9149 - mae: 5.5182 - val_loss: 44.4076 - val_mae: 5.2026\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 42.7361 - mae: 5.0183 - val_loss: 42.8992 - val_mae: 4.9923\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.5611 - mae: 5.2135 - val_loss: 42.9550 - val_mae: 4.9474\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.2825 - mae: 5.1850 - val_loss: 42.8922 - val_mae: 4.9143\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 40.3533 - mae: 4.9477 - val_loss: 41.9458 - val_mae: 4.8266\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 38.0412 - mae: 4.8059 - val_loss: 42.7479 - val_mae: 4.8269\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 38.3629 - mae: 4.8085 - val_loss: 43.3040 - val_mae: 4.8737\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 37.2088 - mae: 4.7539 - val_loss: 41.8058 - val_mae: 4.7813\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.1495 - mae: 4.7338 - val_loss: 42.1362 - val_mae: 4.8121\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 38.1559 - mae: 4.8296 - val_loss: 42.5423 - val_mae: 4.8625\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 38.7313 - mae: 4.9201 - val_loss: 43.0205 - val_mae: 4.8913\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 40.1368 - mae: 4.9301 - val_loss: 41.7579 - val_mae: 4.7852\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.5059 - mae: 4.3590 - val_loss: 42.2937 - val_mae: 4.8375\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5638 - mae: 4.3854 - val_loss: 42.9151 - val_mae: 4.8417\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 36.9384 - mae: 4.8090 - val_loss: 43.6348 - val_mae: 4.8873\n",
            "Epoch 21/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.0487 - mae: 4.7162 - val_loss: 42.3760 - val_mae: 4.8307\n",
            "Epoch 22/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.4369 - mae: 4.3520 - val_loss: 43.4834 - val_mae: 4.8979\n",
            "Epoch 23/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.4616 - mae: 4.5361 - val_loss: 43.2692 - val_mae: 4.9161\n",
            "Epoch 24/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.2448 - mae: 4.6169 - val_loss: 42.8747 - val_mae: 4.8409\n",
            "Epoch 25/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.7243 - mae: 4.1580 - val_loss: 43.1482 - val_mae: 4.8703\n",
            "Epoch 26/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.9137 - mae: 4.4420 - val_loss: 43.2942 - val_mae: 4.8022\n",
            "Epoch 27/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.4660 - mae: 4.4444 - val_loss: 44.2880 - val_mae: 5.0022\n",
            "Epoch 28/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.9574 - mae: 4.4849 - val_loss: 43.7929 - val_mae: 4.8431\n",
            "Epoch 29/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4722 - mae: 4.1221 - val_loss: 43.9878 - val_mae: 4.9141\n",
            "Epoch 30/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.3229 - mae: 4.3280 - val_loss: 43.8637 - val_mae: 4.8382\n",
            "Epoch 31/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.5796 - mae: 4.4505 - val_loss: 43.2805 - val_mae: 4.7524\n",
            "Epoch 32/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.7042 - mae: 4.5631 - val_loss: 43.6325 - val_mae: 4.8269\n",
            "Epoch 33/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.8716 - mae: 4.4250 - val_loss: 43.7187 - val_mae: 4.8386\n",
            "Epoch 34/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.0578 - mae: 4.0907 - val_loss: 43.1516 - val_mae: 4.8567\n",
            "Epoch 35/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.7238 - mae: 4.0614 - val_loss: 44.0868 - val_mae: 4.8773\n",
            "Epoch 36/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.8108 - mae: 4.3092 - val_loss: 44.2568 - val_mae: 4.8614\n",
            "Epoch 37/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.2852 - mae: 4.2842 - val_loss: 43.9885 - val_mae: 4.9107\n",
            "Epoch 38/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.3854 - mae: 4.0886 - val_loss: 42.4229 - val_mae: 4.8571\n",
            "Epoch 39/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.4138 - mae: 4.0874 - val_loss: 43.8848 - val_mae: 4.8530\n",
            "Epoch 40/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1663 - mae: 4.2344 - val_loss: 43.1205 - val_mae: 4.8346\n",
            "Epoch 41/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0009 - mae: 4.0868 - val_loss: 43.0262 - val_mae: 4.8106\n",
            "Epoch 42/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.9563 - mae: 3.7822 - val_loss: 43.1099 - val_mae: 4.7364\n",
            "Epoch 43/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.9228 - mae: 4.1662 - val_loss: 42.2496 - val_mae: 4.7558\n",
            "Epoch 44/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 25.4791 - mae: 3.9172 - val_loss: 43.7278 - val_mae: 4.9069\n",
            "Epoch 45/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4887 - mae: 4.1653 - val_loss: 42.8520 - val_mae: 4.8165\n",
            "Epoch 46/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.0848 - mae: 3.9241 - val_loss: 43.3334 - val_mae: 4.6966\n",
            "Epoch 47/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4834 - mae: 4.0226 - val_loss: 43.2525 - val_mae: 4.7854\n",
            "Epoch 48/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.2758 - mae: 3.8606 - val_loss: 44.4813 - val_mae: 4.7893\n",
            "Epoch 49/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.1409 - mae: 4.5114 - val_loss: 42.8376 - val_mae: 4.7268\n",
            "Epoch 50/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.3616 - mae: 4.0224 - val_loss: 42.4393 - val_mae: 4.8056\n",
            "Epoch 51/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.6772 - mae: 4.0183 - val_loss: 43.3192 - val_mae: 4.8304\n",
            "Epoch 52/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.6329 - mae: 4.2016 - val_loss: 44.6132 - val_mae: 4.9166\n",
            "Epoch 53/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.1511 - mae: 3.9213 - val_loss: 42.8510 - val_mae: 4.7565\n",
            "Epoch 54/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.1047 - mae: 3.9078 - val_loss: 46.0166 - val_mae: 4.9206\n",
            "Epoch 55/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.1605 - mae: 4.2314 - val_loss: 43.2581 - val_mae: 4.8788\n",
            "Epoch 56/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.4749 - mae: 4.0961 - val_loss: 44.8629 - val_mae: 4.8768\n",
            "Epoch 57/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.1190 - mae: 4.1224 - val_loss: 45.1946 - val_mae: 4.9137\n",
            "Epoch 58/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.0793 - mae: 4.0955 - val_loss: 43.6794 - val_mae: 4.7779\n",
            "Epoch 59/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.6087 - mae: 4.1478 - val_loss: 45.7552 - val_mae: 4.8406\n",
            "Epoch 60/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.2925 - mae: 4.1396 - val_loss: 45.5536 - val_mae: 4.9232\n",
            "Epoch 61/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.3996 - mae: 4.0269 - val_loss: 44.8431 - val_mae: 4.8462\n",
            "Epoch 62/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.7055 - mae: 4.0170 - val_loss: 44.9340 - val_mae: 4.9479\n",
            "Epoch 63/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.5746 - mae: 4.0426 - val_loss: 47.8073 - val_mae: 5.0263\n",
            "Epoch 64/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.1363 - mae: 3.7396 - val_loss: 44.8979 - val_mae: 4.8931\n",
            "Epoch 65/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.7542 - mae: 3.7428 - val_loss: 45.5641 - val_mae: 4.8405\n",
            "Epoch 66/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 26.7096 - mae: 4.0201 - val_loss: 44.7571 - val_mae: 4.8508\n",
            "Epoch 67/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.8299 - mae: 3.8325 - val_loss: 44.1840 - val_mae: 4.8610\n",
            "Epoch 68/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 22.8678 - mae: 3.7196 - val_loss: 44.1940 - val_mae: 4.8860\n",
            "Epoch 69/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 25.4601 - mae: 3.8780 - val_loss: 45.5135 - val_mae: 4.8100\n",
            "Epoch 70/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 23.8602 - mae: 3.7218 - val_loss: 44.5647 - val_mae: 4.8098\n",
            "Epoch 71/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.0616 - mae: 3.8795 - val_loss: 45.2681 - val_mae: 4.8255\n",
            "Epoch 72/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 26.5132 - mae: 3.9200 - val_loss: 44.8367 - val_mae: 4.8275\n",
            "Epoch 73/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 23.7602 - mae: 3.7012 - val_loss: 46.0950 - val_mae: 4.9094\n",
            "Epoch 74/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 22.1543 - mae: 3.5916 - val_loss: 47.3517 - val_mae: 4.9738\n",
            "Epoch 75/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 24.8228 - mae: 3.7379 - val_loss: 45.4360 - val_mae: 4.8858\n",
            "Epoch 76/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.4518 - mae: 3.7999 - val_loss: 45.5276 - val_mae: 4.9376\n",
            "Epoch 77/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.9267 - mae: 3.8732 - val_loss: 47.1014 - val_mae: 4.9928\n",
            "Epoch 78/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24.7279 - mae: 3.8585 - val_loss: 44.0525 - val_mae: 4.8483\n",
            "Epoch 79/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 26.5128 - mae: 3.9992 - val_loss: 46.4182 - val_mae: 4.8580\n",
            "Epoch 80/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.3766 - mae: 3.5576 - val_loss: 44.8639 - val_mae: 4.8961\n",
            "Epoch 81/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.4966 - mae: 3.5229 - val_loss: 45.9064 - val_mae: 4.9722\n",
            "Epoch 82/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.0508 - mae: 3.7860 - val_loss: 47.4299 - val_mae: 5.0639\n",
            "Epoch 83/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.5747 - mae: 3.7118 - val_loss: 49.2290 - val_mae: 5.0846\n",
            "Epoch 84/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.7479 - mae: 3.7066 - val_loss: 47.0795 - val_mae: 4.9506\n",
            "Epoch 85/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.1528 - mae: 3.8218 - val_loss: 46.8080 - val_mae: 4.8703\n",
            "Epoch 86/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.5786 - mae: 3.5389 - val_loss: 46.8001 - val_mae: 4.8984\n",
            "Epoch 87/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.7567 - mae: 3.5150 - val_loss: 46.6880 - val_mae: 4.8854\n",
            "Epoch 88/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.2270 - mae: 3.7449 - val_loss: 45.4216 - val_mae: 4.9094\n",
            "Epoch 89/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20.3153 - mae: 3.5159 - val_loss: 44.6231 - val_mae: 4.8807\n",
            "Epoch 90/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 23.0696 - mae: 3.6130 - val_loss: 44.4218 - val_mae: 4.8093\n",
            "Epoch 91/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.1750 - mae: 3.4900 - val_loss: 44.3043 - val_mae: 4.8474\n",
            "Epoch 92/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.1764 - mae: 3.3858 - val_loss: 44.5045 - val_mae: 4.8098\n",
            "Epoch 93/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.2762 - mae: 3.4445 - val_loss: 45.5424 - val_mae: 4.8742\n",
            "Epoch 94/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.5257 - mae: 3.4206 - val_loss: 45.4792 - val_mae: 4.9137\n",
            "Epoch 95/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5166 - mae: 3.9684 - val_loss: 45.1699 - val_mae: 4.8671\n",
            "Epoch 96/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.0968 - mae: 3.6877 - val_loss: 44.6102 - val_mae: 4.7991\n",
            "Epoch 97/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20.5000 - mae: 3.4773 - val_loss: 44.7243 - val_mae: 4.7911\n",
            "Epoch 98/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.3284 - mae: 3.5206 - val_loss: 45.8698 - val_mae: 4.8888\n",
            "Epoch 99/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.2148 - mae: 3.6463 - val_loss: 45.3673 - val_mae: 4.8572\n",
            "Epoch 100/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.6540 - mae: 3.6872 - val_loss: 46.0778 - val_mae: 4.8565\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\n",
            "Fold 5 Training...\n",
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 435.8809 - mae: 18.9938 - val_loss: 145.6215 - val_mae: 9.9227\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 115.8196 - mae: 8.6012 - val_loss: 63.8685 - val_mae: 6.3227\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 69.3558 - mae: 6.6420 - val_loss: 58.6026 - val_mae: 6.1080\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 58.0345 - mae: 6.0541 - val_loss: 52.3515 - val_mae: 5.7063\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 61.9256 - mae: 6.0707 - val_loss: 46.0545 - val_mae: 5.3605\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 53.4715 - mae: 5.5723 - val_loss: 43.2239 - val_mae: 5.1338\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 49.7323 - mae: 5.4092 - val_loss: 42.6613 - val_mae: 5.1055\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 47.0422 - mae: 5.2104 - val_loss: 42.0113 - val_mae: 5.0684\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 43.0358 - mae: 5.0614 - val_loss: 41.2218 - val_mae: 4.9843\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 42.9451 - mae: 5.0955 - val_loss: 40.6372 - val_mae: 4.9461\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 41.2781 - mae: 5.0617 - val_loss: 39.6830 - val_mae: 4.8566\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 41.2154 - mae: 4.9483 - val_loss: 39.7575 - val_mae: 4.8316\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 40.6728 - mae: 5.0032 - val_loss: 40.0728 - val_mae: 4.8861\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 36.9917 - mae: 4.6965 - val_loss: 38.8914 - val_mae: 4.7585\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 41.8591 - mae: 4.8721 - val_loss: 38.4727 - val_mae: 4.7026\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 43.8561 - mae: 5.0475 - val_loss: 38.3065 - val_mae: 4.6347\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 42.4188 - mae: 4.9094 - val_loss: 38.1403 - val_mae: 4.6662\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 37.6719 - mae: 4.7805 - val_loss: 37.7870 - val_mae: 4.6770\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 41.2080 - mae: 4.9865 - val_loss: 38.1103 - val_mae: 4.7037\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 40.9119 - mae: 4.8707 - val_loss: 37.4820 - val_mae: 4.6705\n",
            "Epoch 21/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 35.1752 - mae: 4.6352 - val_loss: 37.6726 - val_mae: 4.6369\n",
            "Epoch 22/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 40.6965 - mae: 4.9666 - val_loss: 36.6510 - val_mae: 4.5487\n",
            "Epoch 23/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 39.3064 - mae: 4.7792 - val_loss: 37.7850 - val_mae: 4.6502\n",
            "Epoch 24/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 33.1021 - mae: 4.5117 - val_loss: 37.6405 - val_mae: 4.6586\n",
            "Epoch 25/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 33.5219 - mae: 4.5664 - val_loss: 37.4865 - val_mae: 4.6864\n",
            "Epoch 26/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 38.2307 - mae: 4.8053 - val_loss: 36.4750 - val_mae: 4.5828\n",
            "Epoch 27/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 36.8936 - mae: 4.6921 - val_loss: 36.0826 - val_mae: 4.5837\n",
            "Epoch 28/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 34.7884 - mae: 4.5983 - val_loss: 36.6606 - val_mae: 4.5854\n",
            "Epoch 29/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 39.8315 - mae: 4.7890 - val_loss: 34.8740 - val_mae: 4.4351\n",
            "Epoch 30/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.7390 - mae: 4.7635 - val_loss: 35.8369 - val_mae: 4.6075\n",
            "Epoch 31/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.3434 - mae: 4.4865 - val_loss: 35.3998 - val_mae: 4.5828\n",
            "Epoch 32/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 32.1925 - mae: 4.3745 - val_loss: 35.3099 - val_mae: 4.5660\n",
            "Epoch 33/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.3256 - mae: 4.4083 - val_loss: 35.4010 - val_mae: 4.5702\n",
            "Epoch 34/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.1326 - mae: 4.4266 - val_loss: 34.4688 - val_mae: 4.5082\n",
            "Epoch 35/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35.4497 - mae: 4.6398 - val_loss: 35.0106 - val_mae: 4.5210\n",
            "Epoch 36/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.9648 - mae: 4.4964 - val_loss: 34.4176 - val_mae: 4.4654\n",
            "Epoch 37/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.0702 - mae: 4.3474 - val_loss: 33.8055 - val_mae: 4.4572\n",
            "Epoch 38/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.6024 - mae: 4.6056 - val_loss: 33.7142 - val_mae: 4.4706\n",
            "Epoch 39/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.1683 - mae: 4.3673 - val_loss: 32.4766 - val_mae: 4.3638\n",
            "Epoch 40/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.7841 - mae: 4.5542 - val_loss: 33.4758 - val_mae: 4.4646\n",
            "Epoch 41/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.0329 - mae: 4.4276 - val_loss: 33.3953 - val_mae: 4.4913\n",
            "Epoch 42/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.9036 - mae: 4.4562 - val_loss: 32.3947 - val_mae: 4.4105\n",
            "Epoch 43/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.7265 - mae: 4.3604 - val_loss: 33.8030 - val_mae: 4.5252\n",
            "Epoch 44/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 35.1130 - mae: 4.6598 - val_loss: 32.6057 - val_mae: 4.4486\n",
            "Epoch 45/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.3504 - mae: 4.2558 - val_loss: 33.0210 - val_mae: 4.4082\n",
            "Epoch 46/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7656 - mae: 4.1488 - val_loss: 32.7368 - val_mae: 4.3569\n",
            "Epoch 47/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.2323 - mae: 4.2760 - val_loss: 33.8304 - val_mae: 4.4693\n",
            "Epoch 48/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.8642 - mae: 4.4074 - val_loss: 32.2663 - val_mae: 4.3524\n",
            "Epoch 49/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5982 - mae: 4.0545 - val_loss: 33.2679 - val_mae: 4.4209\n",
            "Epoch 50/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.6658 - mae: 4.1891 - val_loss: 32.3186 - val_mae: 4.3852\n",
            "Epoch 51/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.0013 - mae: 4.3418 - val_loss: 31.5582 - val_mae: 4.2694\n",
            "Epoch 52/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.1702 - mae: 4.2374 - val_loss: 32.9667 - val_mae: 4.3760\n",
            "Epoch 53/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.1658 - mae: 4.0137 - val_loss: 32.4924 - val_mae: 4.4008\n",
            "Epoch 54/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.8000 - mae: 4.3858 - val_loss: 32.6622 - val_mae: 4.3764\n",
            "Epoch 55/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.7203 - mae: 4.1317 - val_loss: 33.5207 - val_mae: 4.4021\n",
            "Epoch 56/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.8644 - mae: 3.9226 - val_loss: 33.6745 - val_mae: 4.4353\n",
            "Epoch 57/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.0728 - mae: 4.2955 - val_loss: 33.4847 - val_mae: 4.3514\n",
            "Epoch 58/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.5891 - mae: 4.1350 - val_loss: 34.5851 - val_mae: 4.4975\n",
            "Epoch 59/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.1895 - mae: 3.9418 - val_loss: 33.5617 - val_mae: 4.4311\n",
            "Epoch 60/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.3431 - mae: 3.8891 - val_loss: 33.3417 - val_mae: 4.3939\n",
            "Epoch 61/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2952 - mae: 4.1147 - val_loss: 32.8488 - val_mae: 4.3969\n",
            "Epoch 62/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 25.1912 - mae: 3.8190 - val_loss: 34.6132 - val_mae: 4.4777\n",
            "Epoch 63/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4953 - mae: 4.0009 - val_loss: 33.7479 - val_mae: 4.4015\n",
            "Epoch 64/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.1545 - mae: 3.6592 - val_loss: 33.6871 - val_mae: 4.3726\n",
            "Epoch 65/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.4856 - mae: 3.7814 - val_loss: 33.2549 - val_mae: 4.4420\n",
            "Epoch 66/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.7187 - mae: 3.8502 - val_loss: 34.6391 - val_mae: 4.4540\n",
            "Epoch 67/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.5503 - mae: 3.9547 - val_loss: 34.0569 - val_mae: 4.4399\n",
            "Epoch 68/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7820 - mae: 4.2392 - val_loss: 33.6711 - val_mae: 4.3791\n",
            "Epoch 69/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.7336 - mae: 3.8152 - val_loss: 34.1280 - val_mae: 4.4325\n",
            "Epoch 70/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 22.8874 - mae: 3.6724 - val_loss: 33.7319 - val_mae: 4.3689\n",
            "Epoch 71/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.7308 - mae: 3.7745 - val_loss: 34.2177 - val_mae: 4.3683\n",
            "Epoch 72/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.8873 - mae: 3.7807 - val_loss: 35.1027 - val_mae: 4.3750\n",
            "Epoch 73/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.3836 - mae: 3.8360 - val_loss: 33.9528 - val_mae: 4.3558\n",
            "Epoch 74/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.1125 - mae: 4.1125 - val_loss: 34.1840 - val_mae: 4.3217\n",
            "Epoch 75/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.8892 - mae: 3.8163 - val_loss: 33.2375 - val_mae: 4.3157\n",
            "Epoch 76/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.1364 - mae: 3.8663 - val_loss: 33.6142 - val_mae: 4.3498\n",
            "Epoch 77/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 24.9768 - mae: 3.8012 - val_loss: 34.5449 - val_mae: 4.3118\n",
            "Epoch 78/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23.8920 - mae: 3.7853 - val_loss: 34.2502 - val_mae: 4.3456\n",
            "Epoch 79/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 26.2783 - mae: 3.8236 - val_loss: 34.2250 - val_mae: 4.3920\n",
            "Epoch 80/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 26.4346 - mae: 3.9137 - val_loss: 33.3929 - val_mae: 4.3154\n",
            "Epoch 81/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.1103 - mae: 3.7741 - val_loss: 33.6708 - val_mae: 4.3536\n",
            "Epoch 82/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 28.7967 - mae: 4.1300 - val_loss: 33.8717 - val_mae: 4.2863\n",
            "Epoch 83/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 26.7565 - mae: 3.9674 - val_loss: 34.2820 - val_mae: 4.3193\n",
            "Epoch 84/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 24.8202 - mae: 3.7993 - val_loss: 34.9139 - val_mae: 4.3782\n",
            "Epoch 85/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 24.9747 - mae: 3.7989 - val_loss: 34.9022 - val_mae: 4.3926\n",
            "Epoch 86/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 27.6318 - mae: 4.1010 - val_loss: 35.2445 - val_mae: 4.3887\n",
            "Epoch 87/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.1051 - mae: 3.7867 - val_loss: 34.8957 - val_mae: 4.3636\n",
            "Epoch 88/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.2521 - mae: 3.7448 - val_loss: 34.0562 - val_mae: 4.3581\n",
            "Epoch 89/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 23.7012 - mae: 3.6267 - val_loss: 34.6185 - val_mae: 4.3355\n",
            "Epoch 90/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.3246 - mae: 3.7042 - val_loss: 34.0663 - val_mae: 4.2702\n",
            "Epoch 91/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.8061 - mae: 3.6383 - val_loss: 32.9139 - val_mae: 4.2348\n",
            "Epoch 92/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.2340 - mae: 3.9032 - val_loss: 34.0994 - val_mae: 4.2713\n",
            "Epoch 93/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.9381 - mae: 3.9130 - val_loss: 33.4860 - val_mae: 4.2469\n",
            "Epoch 94/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.6140 - mae: 3.8548 - val_loss: 34.5580 - val_mae: 4.3027\n",
            "Epoch 95/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.1389 - mae: 3.7174 - val_loss: 34.2739 - val_mae: 4.3032\n",
            "Epoch 96/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.9496 - mae: 3.8759 - val_loss: 34.8868 - val_mae: 4.3447\n",
            "Epoch 97/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.0671 - mae: 3.7279 - val_loss: 33.7741 - val_mae: 4.2501\n",
            "Epoch 98/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.8587 - mae: 3.4713 - val_loss: 34.6346 - val_mae: 4.3160\n",
            "Epoch 99/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.4214 - mae: 3.4961 - val_loss: 34.4747 - val_mae: 4.2725\n",
            "Epoch 100/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.3632 - mae: 3.5967 - val_loss: 33.0584 - val_mae: 4.2401\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\n",
            "=== Cross-Validated Results ===\n",
            "Fold 1: MSE=48.350, MAE=5.297, RMSE=6.953, R2=0.408\n",
            "Fold 2: MSE=32.805, MAE=4.495, RMSE=5.728, R2=0.514\n",
            "Fold 3: MSE=65.651, MAE=6.087, RMSE=8.103, R2=0.414\n",
            "Fold 4: MSE=46.067, MAE=4.856, RMSE=6.787, R2=0.412\n",
            "Fold 5: MSE=33.047, MAE=4.240, RMSE=5.749, R2=0.645\n",
            "\n",
            "Final Avg Results: MSE=45.184, MAE=4.995, RMSE=6.664, R2=0.479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top N best hyperparameter sets\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print all hyperparameters in the best configuration\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "for param in best_hps.values:\n",
        "    print(f\"{param}: {best_hps.get(param)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb8AjcmACBfX",
        "outputId": "9e396081-1218-4f0f-b663-b5028f96cc2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "num_layers: 2\n",
            "units_0: 64\n",
            "activation: tanh\n",
            "l2: 1.075558357790729e-05\n",
            "use_dropout: True\n",
            "units_1: 96\n",
            "lr: 0.005711014933026775\n",
            "dropout: 0.2\n",
            "units_2: 96\n",
            "units_3: 80\n",
            "units_4: 96\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 12\n",
            "tuner/bracket: 4\n",
            "tuner/round: 3\n",
            "tuner/trial_id: 0138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "print(\"Best Model Summary:\")\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "F7icfQQmUf4b",
        "outputId": "59a395a6-aa3b-41c6-c189-ba848af75509"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m960\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │         \u001b[38;5;34m6,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m97\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,297\u001b[0m (28.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,297</span> (28.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,297\u001b[0m (28.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,297</span> (28.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "shap_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}